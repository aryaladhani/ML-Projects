# # -*- coding: utf-8 -*-
# """ImageClassificationUsingCNN&Pytorch

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/18xs6QNabUVmZmhg4hVByYqwdvwGkyVa9
# """
# !unzip -qq "data.zip"
import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transform
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torch.optim as optim
from tqdm import tqdm

train_data_dir = "data\\4\\train"
val_data_dir="data\\4\\val"
test_data_dir="data\\4\\test"

train_transform = transform.Compose([transform.Resize((224,224)), transform.ToTensor(), transform.Normalize(mean=[0.0,0.0,0.0],std=[1.0,1.0,1.0])])
trainset = torchvision.datasets.ImageFolder(train_data_dir,transform=train_transform)
train_loader = DataLoader(trainset, shuffle = True, batch_size= 16)
valset = torchvision.datasets.ImageFolder(val_data_dir,transform=train_transform)
val_loader = DataLoader(valset, shuffle = True, batch_size= 16)
testset = torchvision.datasets.ImageFolder(test_data_dir,transform=train_transform)
test_loader = DataLoader(testset, shuffle = False, batch_size= 8)

def convblock1(in_dim,out_dim):
  conv = nn.Sequential(
      nn.Conv2d(in_dim,out_dim, kernel_size= 3, stride =1, padding =0),
      nn.BatchNorm2d(out_dim),
      nn.ReLU(),
      nn.Dropout(0.4),
      nn.Conv2d(out_dim, out_dim, kernel_size = 3, stride =1 , padding=0),
      nn.BatchNorm2d(out_dim),
      nn.ReLU(),
      nn.Dropout(0.4)
  )
  return conv
class model1(nn.Module):
  def __init__(self):
    super(model1,self).__init__()
    self.maxpool = nn.MaxPool2d(kernel_size = 3, stride =2)
    self.conv1 = convblock1(3,64)
    self.conv2 = convblock1(64,128)
    self.conv3 = convblock1(128,256)
    self.conv4 = convblock1(256,512)
    self.maxpool2 = nn.MaxPool2d(kernel_size=19, stride =1 )
    self.fc1 = nn.Linear(in_features=512,out_features=128)
    self.fc2 = nn.Linear(in_features =128, out_features =33)

  def forward(self,x):
    x1 = self.conv1(x)
    x2 = self.maxpool(x1)
    x3 = self.conv2(x2)
    x4 = self.maxpool(x3)
    x5 = self.conv3(x4)
    x6 = self.maxpool(x5)
    x7 =self.conv4(x6)
    x7 = self.maxpool2(x7)
    # print(x7.size())
    x8 = x7.view(x.shape[0],-1)
    # print(x8.size())
    x9 = self.fc1(x8)
    x10 = self.fc2(x9)

    return x10

# X = torch.randn((1,3,224,224))
model =model1()
# Y = model(X)
# print(Y.size())

num_epochs = 30
learning_rate= 0.001
momentum = 0.9
weight_decay = 1e-6
if torch.cuda.is_available():
  model = model.cuda()

optimizer = optim.SGD(model.parameters(),lr=learning_rate, momentum =momentum)
loss = nn.CrossEntropyLoss()

def train(net, optimizer, loss_fn, epoch, train_loader):
  running_loss =0
  print(f"running epoch number:{epoch +1}")
  for i, data in enumerate(tqdm(train_loader),0):
    images, labels = data
    if torch.cuda.is_available():
      images, labels = images.cuda(), labels.cuda()
    # print(images,labels)
    optimizer.zero_grad()
    prediction = net(images)
    if torch.cuda.is_available():
      prediction = prediction.cuda()
    loss = loss_fn(prediction, labels)
    running_loss+=loss
    if torch.cuda.is_available():
      loss = loss.cuda()
    loss.backward()
    optimizer.step()
  print(f'After {epoch + 1} epochs, training loss is {running_loss/len(train_loader)}')
  torch.save(model.state_dict(),"/content/drive/MyDrive/Image Classification Using CNN/Dropout/Dropout" + str(epoch)+".pth")
  if torch.cuda.is_available():
    running_loss=running_loss.cuda()
  return running_loss

def test(net, loss_fn, epoch, test_loader):
  running_loss =0
  correct =0
  total = 0

  with torch.no_grad():
    for i,data in enumerate(tqdm(test_loader),0):
      images, labels = data
      if torch.cuda.is_available():
        images, labels = images.cuda(), labels.cuda()
      prediction = net(images)
      loss = loss_fn(prediction, labels)
      _, prediction =  torch.max(prediction.data,1)
      if torch.cuda.is_available():
        prediction, loss  = prediction.cuda(), loss.cuda()
      correct += (prediction==labels).sum().item() 
      total+=labels.size(0)
      # correct = np.float(correct)
      # total = np.float(total)
      # if torch.cuda.is_available():
      #   correct, total = correct.cuda(), total.cuda()
      running_loss += loss
  
  if torch.cuda.is_available():
    running_loss = running_loss.cuda()
  print(f'Accuracy after epoch number {epoch+1} is {100*correct/total} ')
  print(f'After {epoch+1} epochs, test loss is {running_loss/len(test_loader)}')
  return running_loss

training_loss = []
test_loss = []
for i in range(num_epochs):
  loss1 = train(model, optimizer,loss, i, train_loader)
  loss2 = test(model,loss,i,val_loader)
  if torch.cuda.is_available():
    loss1, loss2 = loss1.cuda(), loss2.cuda()
  training_loss.append(loss1)
  test_loss.append(loss2)

